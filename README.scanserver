This file describes the scanserver functionality, the code changes and its behaviour.

To compile with the scanserver functionality, enable WITH_SCANSERVER in the CMake configuration. If you want to directly jump to usage examples, see the "USAGE" section below. For comprehensive purposes the DEVELOPER paragraph describes the new behaviour of the Scan class.

The scanserver is a new method to load and manage scans for 'slam6D', 'show' and some few other tools (so far). It removes all the IO code from the clients and handles it in the server process. This separation offers persistence of scan data and avoids unneccessary reloads of full scans or even reduced versions thereof. By using a caching framework it also transparently handles the available memory given and enables (nearly) endless amounts of data. The client is only required to open the interface, load a directory and start working on those scans without having to alter its workflow (e.g., pre-reduce them) to accomodate huge data volumes.

If you have questions or problems (or both), contact Thomas Escher <tescher@uos.de>.



USAGE:

1. General

Start the scanserver once:
  bin/scanserver &
  
Do all the normal work as you would normally do:
  bin/slam6D dat
  bin/show dat

2. Changing the available memory size

Changing the cache memory size used by scan data (close to half the system memory usually always works):

  bin/scanserver -c 3500   (for 8GB RAM)

If you intend to reload the full scans for different reduction parameters or just have too much memory/disk space, enable binary scan caching. It saves the full scans as long as the range or height parameters aren't touched, which would cause a full reload:

  bin/scanserver -b

If your dataset contains many scans and loops (e.g. hannover with 468 scans), the default data memory (150M) won't be enough to hold all the animation frames and you need to increase it:

  bin/scanserver -d 250

3. Altering the shared memory on your linux system (bus_error)

If you receive a bus_error, the size of your shared memory is too small and the requested allocation was too big. This is resolved via remounting your shm device. Default should be half your RAM. It is not advised to increase this to more than 75-80% of your ram to avoid swapping.

  sudo mount -o remount,size=4000M /dev/shm   (for 8GB RAM)

4. Using the octtree serialization feature in show with scanserver

The octtree serialization behaves slightly different than before. Since the scanserver caches octtrees between show calls the loading of octtrees only becomes relevant if no octtrees are in cache and have to be created from the scan itself. If this has been done once before and the octtrees have been saved via --saveOct before this can be used to speed up the octtree loading with --loadOct.

  bin/show dat --saveOct (once, or everytime you know you will be able to save more than before)
  bin/show dat --loadOct (once for every scanserver (re)start)
  bin/show dat           (otherwise, octtrees are cached)

DEVELOPER:

Regarding the code changes, the scanserver code separates the old code from the new one via means of WITH_SCANSERVER-ifdefs in the case of scan loading and data access code. To use it in a program it is required to open the ClientInterface, which communicates to the scanserver process. The next step is to open a directory via readScans or readScansRedSearch if you require reduction of the scan data. At this point you can request each bit of scan data at any point you like.y

Using the Scan class now requires a bit of attention regarding which data is computed when. Generally all the full data (xyz/rgb) is fetched the moment it is requested, regardless of a direct call to getXYZ()/getRGB(), or interally via other data altering functions like transform(). The next step of on-demand calculation starts when requesting the reduced or original points ('original' being the only-transMatOrg-transformed reduced point set in world coordinates, which the SearchTrees uses for closest point lookup, 'reduced' in constrast receiving all the consequent transformation steps and being the point set the matching algorithm traverses) if the directory has been opened via 'readScansRedSearch' (and setting the reduction parameters, more specifically). In this step the code checks if it can fetch already reduced points from a prior run and simply copying the original points into the reduced ones. If not, it calls calcReducedPoints(), transform() for the initial world coordinate transformation, and saves the reduced points in the original ones for SearchTrees and aforemetioned caching of reduced points. The last step of on-demand calculation is the creation of a SearchTree. The original points are requested and, if neccessary, created as described before, and a SearchTree is calculated. At this point only a managed version of the KD-tree is implemented to work with the new data access method.

In contrast to the now default on-demand reduction behaviour of Scan there is still the possibility of manually calling calcReducedPoints(), transform() and toGlobal() which represents this exact step. In neither of these cases the original points are created and copied from the reduced ones, so copyReducedToOriginal() has to be invoked if they're needed for storing or SearchTrees. TODO: put this into global and change all tools to use this? safer behaviour. Keep in mind the Scan class is the core component of slam6D and primarily represents its behaviour.

Metascans are handled transparently without copying any of the points. It now builds up a multi-scan version of the new managed (in context of cache managed, e.g., requesting the DataXYZ instances) KD-tree if a SearchTree is requested from the scan, holding all parts of the metascan in memory and pointing to their points instead of its own (non-existing) original points. This meta-SearchTree is used in loopclosing and graph-SLAM. In the case of loop closing two metascans are matched against each other, requiring one metascan to traverse its (non-existant) reduced points. In this case the getPtPairs function splits up the traverse and iterates over each scan in the metascan, all while being in a threaded call.

If compiled with the WITH_METRICS option, both scanserver and slam6D will output additional and detailed information about time usage in different parts of the code. Since slam6D now handles the scan loading and reduction on demand while matching, the metric functionality is needed to differentiate between those. Currently only singlethreaded versions of the old version without scanserver records detailed time metrics since the scanserver also works singlethreaded. In addition to that the time measurement of a multithreaded system has to be calculated differently.



IMPLEMENTATION STATUS:

Currently only 'slam6D' and 'show' are working with the scanserver.

'scan_red' has been updated too, but rendered moot with the scanserver. 'scan_diff' does not work due to its dependance on the simple versions of get(no/pt)pairs and building a KD-tree over the reduced points. 'caliboard' has been updated and compiles, but is yet untested.

Since the scanserver handles the disk IO now and the filtering has been optimized, not all ScanIOs are updated yet. Just copy and paste and change the minor parts about reading the input lines.
Working: uos, uos_rgb, ks, ks_rgb, riegl_txt, riegl_rgb (or just do an 'ls src/scanserver/scan_io')
